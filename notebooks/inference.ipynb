{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emerhack_eda_2_inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dcc2a5ac72c4410b9654fe4ec8441101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_73984031526841808741a95844896e90",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa180367649546a7b61bf078e95aff40",
              "IPY_MODEL_54a2318fd95e4631854f1ac258de4dad"
            ]
          }
        },
        "73984031526841808741a95844896e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa180367649546a7b61bf078e95aff40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c36b370159b4368a786308e089cdbc7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 123,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 123,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_940832be36b7494683bc5161fa1d558c"
          }
        },
        "54a2318fd95e4631854f1ac258de4dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f3b28ba162b48f8b74346977b769297",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 123/123 [00:57&lt;00:00,  2.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b480666723e14c7d8c3a18e438b0a12d"
          }
        },
        "5c36b370159b4368a786308e089cdbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "940832be36b7494683bc5161fa1d558c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f3b28ba162b48f8b74346977b769297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b480666723e14c7d8c3a18e438b0a12d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut7LGUcRlphd",
        "outputId": "41547e2d-0e3f-470e-95a2-f5a7f4f7dab8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May 30 06:52:27 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFw5djjZsMYO",
        "outputId": "05017998-912f-48b9-9b39-f5536752b9c1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\r\u001b[K     |▏                               | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 21.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 23.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 18.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 16.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 17.7MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 14.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 15.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 15.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 14.8MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 14.8MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 14.8MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 14.8MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 14.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 14.8MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 14.8MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 296kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 14.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 430kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 593kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 696kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 727kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 757kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 829kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 860kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 890kB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 962kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 993kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.6MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.9MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.0MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.2MB 14.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 14.8MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH3122cWE8Yd",
        "outputId": "e4661690-b81d-42d4-dade-77a494843e01"
      },
      "source": [
        "#https://drive.google.com/file/d/1NXHAAHDdQ9iO4OUFEuYgQegYU56s2Myb/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1QRlx8_hNiL7rWc8XhQd0Zc_BeAlxOm73/view?usp=sharing\n",
        "\n",
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1QRlx8_hNiL7rWc8XhQd0Zc_BeAlxOm73\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1QRlx8_hNiL7rWc8XhQd0Zc_BeAlxOm73\" -o smpl.zip\n",
        "!unzip -P dszWwT8x -qq smpl.zip \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   2566      0 --:--:-- --:--:-- --:--:--  2566\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  129M    0  129M    0     0  83.6M      0 --:--:--  0:00:01 --:--:--  169M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4nOll4NDeMJ",
        "outputId": "64bd6251-bbae-4051-b9b4-b0530bd3ae20"
      },
      "source": [
        "#https://drive.google.com/file/d/1eNhgPsH8omsakIaGUOjkDv-8FOixIKv0/view?usp=sharing\n",
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1eNhgPsH8omsakIaGUOjkDv-8FOixIKv0\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1eNhgPsH8omsakIaGUOjkDv-8FOixIKv0\" -o features.csv\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1707      0 --:--:-- --:--:-- --:--:--  1700\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  235M    0  235M    0     0   123M      0 --:--:--  0:00:01 --:--:--  243M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg-etpf-H05V",
        "outputId": "37fde297-6067-4556-f69f-cbea3e85ded3"
      },
      "source": [
        "#https://drive.google.com/file/d/1eNhgPsH8omsakIaGUOjkDv-8FOixIKv0/view?usp=sharing\n",
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1OrzgFXiM8yLk01qLNypaZV6_zeZmNU4I\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1OrzgFXiM8yLk01qLNypaZV6_zeZmNU4I\" -o lena_ai_trans.pth\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0    693      0 --:--:-- --:--:-- --:--:--   693\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1502k  100 1502k    0     0  1475k      0  0:00:01  0:00:01 --:--:-- 1475k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XaSC3OTO5Ra",
        "outputId": "b0c051f1-88e5-4ed8-9b0c-94bf19a9f124"
      },
      "source": [
        "%%writefile features.py\n",
        "# Файл содержит спискок всех фич с описанием типа\n",
        "\n",
        "features = {\n",
        "    \"train.csv\": {\n",
        "        \"year\": ((\"numeric\", None), (\"categorical\", None)),\n",
        "        \"station_id\": ((\"categorical\", None),),\n",
        "        \"day\": ((\"numeric\", None), (\"categorical\", None)),\n",
        "        \"ice_jam\": ((\"numeric\", None),),\n",
        "    },\n",
        "    \"hydro_1day.csv\": {\n",
        "        \"year\": ((\"numeric\", None), (\"categorical\", None)),\n",
        "        \"station_id\": ((\"categorical\", None),),\n",
        "        \"month\": ((\"numeric\", None), (\"categorical\", None)),\n",
        "        \"day\": ((\"numeric\", None), (\"categorical\", None)),\n",
        "        \"date\": ((\"date\", None),),\n",
        "        \"stage_avg\": ((\"numeric\", None),),\n",
        "        \"stage_min\": ((\"numeric\", None),),\n",
        "        \"stage_max\": ((\"numeric\", None),),\n",
        "        \"temp\": ((\"numeric\", None),),\n",
        "        \"water_code\": ((\"water_codes\", None),),\n",
        "        \"ice_thickness\": ((\"numeric\", None),),\n",
        "        \"snow_height\": ((\"numeric\", None),),\n",
        "        \"place\": ((\"categorical\", None),),\n",
        "        \"discharge\": ((\"numeric\", None),),\n",
        "    },\n",
        "    \"meteo_1day.csv\": {\n",
        "        \"station_id\": ((\"categorical\", None),),\n",
        "        \"year\": ((\"numeric\", None), (\"categorical\", None)),\n",
        "        \"month\": ((\"numeric\", None), (\"categorical\", None)),\n",
        "        \"day\": ((\"numeric\", None), (\"categorical\", None)),\n",
        "        \"route_type\": ((\"categorical\", None),),\n",
        "        \"snow_coverage_near_station\": ((\"numeric\", None),),\n",
        "        \"snow_coverage_route\": ((\"numeric\", None),),\n",
        "        \"ice_crust_route\": ((\"numeric\", None),),\n",
        "        \"snow_height_aver\": ((\"numeric\", None),),\n",
        "        \"snow_height_max\": ((\"numeric\", None),),\n",
        "        \"snow_height_min\": ((\"numeric\", None),),\n",
        "        \"snow_density_aver\": ((\"numeric\", None),),\n",
        "        \"ice_crust_aver\": ((\"numeric\", None),),\n",
        "        \"snow_saturated_thickness\": ((\"numeric\", None),),\n",
        "        \"water_thickness\": ((\"numeric\", None),),\n",
        "        \"water_in_snow\": ((\"numeric\", None),),\n",
        "        \"water_total\": ((\"numeric\", None),),\n",
        "        \"snow_coverage_charact\": ((\"categorical\", None),),\n",
        "        \"snow_charact\": ((\"categorical\", None),),\n",
        "        \"snow_height\": ((\"numeric\", 9999),),\n",
        "        \"snow_coverage_station\": ((\"numeric\", None),),\n",
        "        \"snow_height_q1\": ((\"categorical\", None),),\n",
        "        \"snow_height_q2\": ((\"categorical\", None),),\n",
        "        \"snow_height_q3\": ((\"categorical\", None),),\n",
        "        \"temperature_20cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_20cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_40cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_40cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_80cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_80cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_120cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_120cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_160cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_160cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_240cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_240cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_320cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_320cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_ks_5cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_ks_5cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_ks_10cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_ks_10cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_ks_15cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_ks_15cm_qual\": ((\"categorical\", None),),\n",
        "        \"temperature_ks_20cm\": ((\"numeric\", 9999),),\n",
        "        \"temperature_ks_20cm_qual\": ((\"categorical\", None),),\n",
        "        \"date\": ((\"date\", None),),\n",
        "    },\n",
        "    \"hydro_coord.csv\": {\n",
        "        \"station_id\": ((\"categorical\", None),),\n",
        "        \"name\": ((\"drop\", None),),\n",
        "        \"lat\": ((\"numeric\", None),),\n",
        "        \"lon\": ((\"numeric\", None),),\n",
        "        \"distance_from_source\": ((\"numeric\", None),),\n",
        "        \"drainage_area\": ((\"numeric\", None),),\n",
        "        \"z_null\": ((\"numeric\", None),),\n",
        "    },\n",
        "    \"meteo_coord.csv\": {\n",
        "        \"station_id\": ((\"categorical\", None),),\n",
        "        \"name\": ((\"drop\", None),),\n",
        "        \"lat\": ((\"numeric\", None),),\n",
        "        \"lon\": ((\"numeric\", None),),\n",
        "        \"z\": ((\"numeric\", None),),\n",
        "    },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing features.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g8U1JtSO43Y",
        "outputId": "fd99b3fa-04d2-4353-b982-bdb15faef9f6"
      },
      "source": [
        "%%writefile data_loading.py\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from geopy.distance import geodesic\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler  # feature_range=(-1,1)\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT_DIR = Path('./')\n",
        "TRACK1_DIR = ROOT_DIR / \"track_1\"\n",
        "DATA_DIR = ROOT_DIR\n",
        "\n",
        "from features import features\n",
        "\n",
        "# Подтянем ближайшую к гидростанции метеостанцию\n",
        "\n",
        "\n",
        "def make_water_state_encoder(base_path=TRACK1_DIR, postfix=\"\"):\n",
        "    wdf = pd.read_csv(base_path / (\"reference_water_codes\" + postfix + \".csv\"))\n",
        "    labels = wdf[\"water_code\"].values\n",
        "    le = LabelEncoder()\n",
        "    le.fit(labels)\n",
        "    joblib.dump(le, DATA_DIR / \"dict_water_codes.joblib\")\n",
        "\n",
        "    return len(list(le.classes_))\n",
        "\n",
        "\n",
        "def apply_water_state_encoder(df):\n",
        "    le = joblib.load(DATA_DIR / \"dict_water_codes.joblib\")\n",
        "    # make dict from label encoder\n",
        "    # ref code -> int code\n",
        "    rev_mapping = dict(zip(range(len(le.classes_)), le.classes_))\n",
        "    n = len(list(le.classes_))\n",
        "\n",
        "    # make new columns\n",
        "    for i in range(n):\n",
        "        df[\"fixed_water_code_\" + str(i)] = (\n",
        "            df[\"water_code\"]\n",
        "            .fillna(\"\")\n",
        "            .str.split(\",\")\n",
        "            .apply(lambda s: str(rev_mapping[i]) in s if s else -1)\n",
        "            .astype(\"int32\")\n",
        "        )\n",
        "\n",
        "    df = df.drop(columns=[\"water_code\"])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def fix_column(df, column, column_type, nan_encoding):\n",
        "    if column_type == \"numeric\":\n",
        "        df[f\"fixed_{column}_{column_type}\"] = df[column]\n",
        "        df[f\"fixed_{column}_{column_type}\"] = df[f\"fixed_{column}_{column_type}\"].astype(\"float32\")\n",
        "        if nan_encoding:\n",
        "            df[f\"fixed_{column}_{column_type}\"] = df[f\"fixed_{column}_{column_type}\"].replace(nan_encoding, None)\n",
        "        df[f\"fixed_{column}_{column_type}\"] = df[f\"fixed_{column}_{column_type}\"].fillna(\n",
        "            df[f\"fixed_{column}_{column_type}\"].median()\n",
        "        )\n",
        "\n",
        "    elif column_type == \"categorical\":\n",
        "        df[f\"fixed_{column}_{column_type}\"] = df[column]\n",
        "        if nan_encoding:\n",
        "            df[f\"fixed_{column}_{column_type}\"] = df[f\"fixed_{column}_{column_type}\"].replace(nan_encoding, None)\n",
        "        df[f\"fixed_{column}_{column_type}\"] = df[f\"fixed_{column}_{column_type}\"].fillna(-1)\n",
        "        df[f\"fixed_{column}_{column_type}\"] = df[f\"fixed_{column}_{column_type}\"].astype(\"category\")\n",
        "\n",
        "    elif column_type == \"water_codes\":\n",
        "        apply_water_state_encoder(df)\n",
        "\n",
        "    elif column_type == \"drop\":\n",
        "        pass\n",
        "\n",
        "    elif column_type == \"date\":\n",
        "        df[f\"fixed_{column}_{column_type}\"] = df[column]\n",
        "        df[f\"fixed_{column}_{column_type}\"] = pd.to_datetime(df[f\"fixed_{column}_{column_type}\"])\n",
        "\n",
        "\n",
        "def fix_df(df, df_name):\n",
        "\n",
        "    df_features = features[df_name]\n",
        "    columns = df.columns.copy()\n",
        "    for column in columns:\n",
        "        for column_type, nan_encoding in df_features[column]:\n",
        "            fix_column(df=df, column=column, column_type=column_type, nan_encoding=nan_encoding)\n",
        "        df = df.drop(columns=[column])\n",
        "\n",
        "    assert not df.isna().any().all()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_table(name):\n",
        "    table = pd.read_csv(TRACK1_DIR / name)\n",
        "    fixed_table = fix_df(table, name)\n",
        "\n",
        "    return fixed_table\n",
        "\n",
        "\n",
        "def merge_closest_meteo_to_hydro(hydro, meteo):\n",
        "    assert len(hydro) == hydro[\"hydro_fixed_station_id_categorical\"].nunique()\n",
        "    assert len(meteo) == meteo[\"meteo_fixed_station_id_categorical\"].nunique()\n",
        "\n",
        "    hydro[\"hydro_closest_meteo_station_id\"] = 0\n",
        "    for i, row in hydro.iterrows():\n",
        "        hydro_point = row[\"hydro_lat_lon\"]\n",
        "\n",
        "        min_dist = float(\"inf\")\n",
        "        min_j = 0\n",
        "        for j, row in meteo.iterrows():\n",
        "            meteo_point = row[\"meteo_lat_lon\"]\n",
        "            if geodesic(hydro_point, meteo_point).km < min_dist:\n",
        "                min_dist = geodesic(hydro_point, meteo_point).km\n",
        "                min_j = j\n",
        "\n",
        "        hydro.loc[i, \"hydro_closest_meteo_station_id\"] = meteo.iloc[min_j][\"meteo_fixed_station_id_categorical\"]\n",
        "\n",
        "    assert (hydro[\"hydro_closest_meteo_station_id\"] != 0).all()\n",
        "\n",
        "    hydro = hydro.merge(meteo, left_on=\"hydro_closest_meteo_station_id\", right_on=\"meteo_fixed_station_id_categorical\")\n",
        "\n",
        "    return hydro\n",
        "\n",
        "\n",
        "def merge_tables(hydro_1day, meteo_1day, hydro_coord, meteo_coord):\n",
        "    hydro_coord = hydro_coord.add_prefix(\"hydro_\")\n",
        "    meteo_coord = meteo_coord.add_prefix(\"meteo_\")\n",
        "    hydro_1day = hydro_1day.add_prefix(\"hydro_\")\n",
        "    meteo_1day = meteo_1day.add_prefix(\"meteo_\")\n",
        "\n",
        "    hydro_coord[\"hydro_lat_lon\"] = hydro_coord[[\"hydro_fixed_lat_numeric\", \"hydro_fixed_lon_numeric\"]].apply(\n",
        "        tuple, axis=1\n",
        "    )\n",
        "    meteo_coord[\"meteo_lat_lon\"] = meteo_coord[[\"meteo_fixed_lat_numeric\", \"meteo_fixed_lon_numeric\"]].apply(\n",
        "        tuple, axis=1\n",
        "    )\n",
        "\n",
        "    print(\"Merging closest stations\")\n",
        "    hydro_coord_with_closest_meteo_coord = merge_closest_meteo_to_hydro(hydro_coord, meteo_coord)\n",
        "\n",
        "    hydro_1day = hydro_1day.merge(\n",
        "        hydro_coord_with_closest_meteo_coord[[\"hydro_fixed_station_id_categorical\", \"hydro_closest_meteo_station_id\"]]\n",
        "    )\n",
        "\n",
        "    hydro_1day = hydro_1day.merge(\n",
        "        meteo_1day,\n",
        "        left_on=[\"hydro_closest_meteo_station_id\", \"hydro_fixed_date_date\"],\n",
        "        right_on=[\"meteo_fixed_station_id_categorical\", \"meteo_fixed_date_date\"],\n",
        "    )\n",
        "\n",
        "    hydro_1day = hydro_1day.merge(hydro_coord_with_closest_meteo_coord, on=\"hydro_fixed_station_id_categorical\")\n",
        "\n",
        "    return hydro_1day\n",
        "\n",
        "\n",
        "def add_keys(features_df):\n",
        "    features_df[\"year\"] = features_df[\"hydro_fixed_year_categorical\"]\n",
        "    features_df[\"day\"] = features_df[\"hydro_fixed_day_categorical\"]\n",
        "    features_df[\"hydro_station_id\"] = features_df[\"hydro_fixed_station_id_categorical\"]\n",
        "\n",
        "    return features_df\n",
        "\n",
        "\n",
        "def scale_numerical_features(features_df):\n",
        "    numerical_cols = [col for col in features_df.columns if col.endswith(\"_numeric\")]\n",
        "    scaler = StandardScaler()\n",
        "    features_df[numerical_cols] = scaler.fit_transform(features_df[numerical_cols])\n",
        "\n",
        "    return features_df\n",
        "\n",
        "\n",
        "def encode_categorical_features(features_df):\n",
        "    categorical_cols = [col for col in features_df.columns if col.endswith(\"_categorical\")]\n",
        "    for cat_col in categorical_cols:\n",
        "        encoder = LabelEncoder()\n",
        "        features_df[cat_col] = encoder.fit_transform(features_df[cat_col])\n",
        "\n",
        "    return features_df\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    make_water_state_encoder()\n",
        "    hydro_1day = load_table(\"hydro_1day.csv\")\n",
        "    data = load_table(\"train.csv\")\n",
        "    meteo_1day = load_table(\"meteo_1day.csv\")\n",
        "    hydro_coord = load_table(\"hydro_coord.csv\")\n",
        "    meteo_coord = load_table(\"meteo_coord.csv\")\n",
        "    features_df = merge_tables(hydro_1day, meteo_1day, hydro_coord, meteo_coord)\n",
        "    features_df = add_keys(features_df)\n",
        "    features_df = scale_numerical_features(features_df)\n",
        "    features_df = encode_categorical_features(features_df)\n",
        "    bad_columns = [col for col in features_df.columns if (col.endswith(\"_x\") or col.endswith(\"_y\"))] + [\n",
        "        \"hydro_lat_lon\",\n",
        "        \"meteo_lat_lon\",\n",
        "    ]\n",
        "    features_df = features_df.drop(columns=bad_columns)\n",
        "    features_df.to_csv(DATA_DIR / \"features.csv\")\n",
        "    data.to_csv(DATA_DIR / \"train.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing data_loading.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDN1RD6abrnT",
        "outputId": "5d9231f8-9ba7-4d87-90b6-1e289f590450"
      },
      "source": [
        "#!python data_loading.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Merging closest stations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTqnhfpZDN8b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train = pd.read_csv('track_1/train.csv')\n",
        "test = pd.read_csv('track_1/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0k8r_evRBNc"
      },
      "source": [
        "features_df = pd.read_csv('features.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHQk5l-EDM8-"
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LenaDataset(Dataset):\n",
        "    def __init__(self, label_df, full_df, cat_cols, num_cols, last_day_previous_year=365 - (31 + 30 + 31)):\n",
        "        self.label_df = label_df.copy()\n",
        "        self.full_df = full_df.copy()\n",
        "\n",
        "        self.cat_cols = list(cat_cols)\n",
        "        self.num_cols = list(num_cols)\n",
        "\n",
        "        self.last_day_previous_year = last_day_previous_year\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.label_df.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        station = self.label_df.station_id.values[idx]\n",
        "        year = self.label_df.year.values[idx]\n",
        "        day = self.label_df.day.values[idx]\n",
        "        target = self.label_df.ice_jam.values[idx]\n",
        "        prev_year = year - 1\n",
        "        part_index1 = (self.full_df.year == prev_year) & (self.full_df.day > self.last_day_previous_year)\n",
        "        part_index2 = (self.full_df.year == year) & (self.full_df.day < 31 + 30 + 31)\n",
        "        part_index3 = self.full_df.hydro_station_id == station\n",
        "        any_id = self.full_df.loc[part_index3,'hydro_fixed_station_id_categorical'].values[0]\n",
        "        feat_matrix = self.full_df.loc[(part_index1 | part_index2) & part_index3, self.cat_cols + self.num_cols].values\n",
        "        new_feat_matrix = np.zeros((139, feat_matrix.shape[1]))\n",
        "        new_feat_matrix[-feat_matrix.shape[0] :] = feat_matrix\n",
        "        return {\"x\": new_feat_matrix, \"y\": target, \"day\": day, \"station\": any_id}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAACTm-1E8vv"
      },
      "source": [
        "numerical_features = [c for c in features_df if c.endswith('numeric')] +\\\n",
        "                     [c for c in features_df if c.startswith('hydro_fixed_water_code')]\n",
        "categorical_features = [c for c in features_df if c.endswith('categorical')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlpi_RkpE1hJ",
        "outputId": "232db52c-bb56-4ff9-d718-6a3fa6950716"
      },
      "source": [
        "ds = LenaDataset(train, features_df, categorical_features, numerical_features)\n",
        "ds[2256]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'day': 13, 'station': 6, 'x': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "        [15.,  6.,  0., ...,  0.,  0.,  0.],\n",
              "        ...,\n",
              "        [14.,  6.,  8., ...,  0.,  0.,  0.],\n",
              "        [14.,  6.,  8., ...,  0.,  0.,  0.],\n",
              "        [14.,  6.,  8., ...,  0.,  0.,  0.]]), 'y': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D7z1kqIIGU4",
        "outputId": "6fdeb137-caea-4255-b0d3-8885d2c709a7"
      },
      "source": [
        "transactions_cat_features = {}\n",
        "\n",
        "def emb_sz_rule(n_cat:int)->int: return min(600, round(1.6 * n_cat**0.56))\n",
        "\n",
        "for cat_col in categorical_features:\n",
        "    cardinality = features_df[cat_col].max() + 1\n",
        "    transactions_cat_features[cat_col] = (cardinality, emb_sz_rule(cardinality))\n",
        "transactions_cat_features['day_target_categorical'] = (45, emb_sz_rule(45))\n",
        "transactions_cat_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'day_target_categorical': (45, 13),\n",
              " 'hydro_fixed_day_categorical': (257, 36),\n",
              " 'hydro_fixed_month_categorical': (9, 5),\n",
              " 'hydro_fixed_place_categorical': (4, 3),\n",
              " 'hydro_fixed_station_id_categorical': (26, 10),\n",
              " 'hydro_fixed_year_categorical': (35, 12),\n",
              " 'meteo_fixed_day_categorical': (257, 36),\n",
              " 'meteo_fixed_month_categorical': (9, 5),\n",
              " 'meteo_fixed_route_type_categorical': (4, 3),\n",
              " 'meteo_fixed_snow_charact_categorical': (9, 5),\n",
              " 'meteo_fixed_snow_coverage_charact_categorical': (10, 6),\n",
              " 'meteo_fixed_snow_height_q1_categorical': (5, 4),\n",
              " 'meteo_fixed_snow_height_q2_categorical': (2, 2),\n",
              " 'meteo_fixed_snow_height_q3_categorical': (2, 2),\n",
              " 'meteo_fixed_temperature_120cm_qual_categorical': (6, 4),\n",
              " 'meteo_fixed_temperature_160cm_qual_categorical': (6, 4),\n",
              " 'meteo_fixed_temperature_20cm_qual_categorical': (5, 4),\n",
              " 'meteo_fixed_temperature_240cm_qual_categorical': (7, 5),\n",
              " 'meteo_fixed_temperature_320cm_qual_categorical': (6, 4),\n",
              " 'meteo_fixed_temperature_40cm_qual_categorical': (6, 4),\n",
              " 'meteo_fixed_temperature_80cm_qual_categorical': (7, 5),\n",
              " 'meteo_fixed_temperature_ks_10cm_qual_categorical': (3, 3),\n",
              " 'meteo_fixed_temperature_ks_15cm_qual_categorical': (3, 3),\n",
              " 'meteo_fixed_temperature_ks_20cm_qual_categorical': (3, 3),\n",
              " 'meteo_fixed_temperature_ks_5cm_qual_categorical': (3, 3),\n",
              " 'meteo_fixed_year_categorical': (35, 12)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAW37MKDHKZ6"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AlbertConfig, AlbertModel\n",
        "\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KxrameVXCdf"
      },
      "source": [
        "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score\n",
        "\n",
        "def threshold_search(y_true, y_proba):\n",
        "    precision , recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
        "    thresholds = np.append(thresholds, 1.001) \n",
        "    F = 2 / (1/precision + 1/recall)\n",
        "    best_score = np.max(F)\n",
        "    best_th = thresholds[np.argmax(F)]\n",
        "    return best_th , best_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk2ZY78FabS4"
      },
      "source": [
        "def binary_focal_loss_with_logits(\n",
        "        input: torch.Tensor,\n",
        "        target: torch.Tensor,\n",
        "        alpha: float = .25,\n",
        "        gamma: float = 2.0,\n",
        "        reduction: str = 'none',\n",
        "        eps: float = 1e-8) -> torch.Tensor:\n",
        "    r\"\"\"Function that computes Binary Focal loss.\n",
        "    .. math::\n",
        "        \\text{FL}(p_t) = -\\alpha_t (1 - p_t)^{\\gamma} \\, \\text{log}(p_t)\n",
        "    where:\n",
        "       - :math:`p_t` is the model's estimated probability for each class.\n",
        "    Args:\n",
        "        input (torch.Tensor): input data tensor with shape :math:`(N, 1, *)`.\n",
        "        target (torch.Tensor): the target tensor with shape :math:`(N, 1, *)`.\n",
        "        alpha (float): Weighting factor for the rare class :math:`\\alpha \\in [0, 1]`. Default: 0.25.\n",
        "        gamma (float): Focusing parameter :math:`\\gamma >= 0`. Default: 2.0.\n",
        "        reduction (str, optional): Specifies the reduction to apply to the. Default: 'none'.\n",
        "        eps (float): for numerically stability when dividing. Default: 1e-8.\n",
        "    Returns:\n",
        "        torch.tensor: the computed loss.\n",
        "    Examples:\n",
        "        >>> num_classes = 1\n",
        "        >>> kwargs = {\"alpha\": 0.25, \"gamma\": 2.0, \"reduction\": 'mean'}\n",
        "        >>> logits = torch.tensor([[[[6.325]]],[[[5.26]]],[[[87.49]]]])\n",
        "        >>> labels = torch.tensor([[[1.]],[[1.]],[[0.]]])\n",
        "        >>> binary_focal_loss_with_logits(logits, labels, **kwargs)\n",
        "        tensor(4.6052)\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(input, torch.Tensor):\n",
        "        raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
        "                        .format(type(input)))\n",
        "\n",
        "    if not len(input.shape) >= 2:\n",
        "        raise ValueError(\"Invalid input shape, we expect BxCx*. Got: {}\"\n",
        "                         .format(input.shape))\n",
        "\n",
        "    if input.size(0) != target.size(0):\n",
        "        raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n",
        "                         .format(input.size(0), target.size(0)))\n",
        "\n",
        "    probs = torch.sigmoid(input)\n",
        "    target = target.unsqueeze(dim=1)\n",
        "    loss_tmp = - alpha * torch.pow((1. - probs + eps), gamma) * target * torch.log(probs + eps) \\\n",
        "               - (1 - alpha) * torch.pow(probs + eps, gamma) * (1. - target) * torch.log(1. - probs + eps)\n",
        "\n",
        "    loss_tmp = loss_tmp.squeeze(dim=1)\n",
        "\n",
        "    if reduction == 'none':\n",
        "        loss = loss_tmp\n",
        "    elif reduction == 'mean':\n",
        "        loss = torch.mean(loss_tmp)\n",
        "    elif reduction == 'sum':\n",
        "        loss = torch.sum(loss_tmp)\n",
        "    else:\n",
        "        raise NotImplementedError(\"Invalid reduction mode: {}\"\n",
        "                                  .format(reduction))\n",
        "    return loss\n",
        "\n",
        "\n",
        "class BinaryFocalLossWithLogits(nn.Module):\n",
        "    r\"\"\"Criterion that computes Focal loss.\n",
        "    According to :cite:`lin2017focal`, the Focal loss is computed as follows:\n",
        "    .. math::\n",
        "        \\text{FL}(p_t) = -\\alpha_t (1 - p_t)^{\\gamma} \\, \\text{log}(p_t)\n",
        "    where:\n",
        "       - :math:`p_t` is the model's estimated probability for each class.\n",
        "    Args:\n",
        "        alpha (float): Weighting factor for the rare class :math:`\\alpha \\in [0, 1]`.\n",
        "        gamma (float): Focusing parameter :math:`\\gamma >= 0`.\n",
        "        reduction (str, optional): Specifies the reduction to apply to the\n",
        "         output: ‘none’ | ‘mean’ | ‘sum’. ‘none’: no reduction will be applied,\n",
        "         ‘mean’: the sum of the output will be divided by the number of elements\n",
        "         in the output, ‘sum’: the output will be summed. Default: ‘none’.\n",
        "    Shape:\n",
        "        - Input: :math:`(N, 1, *)`.\n",
        "        - Target: :math:`(N, 1, *)`.\n",
        "    Examples:\n",
        "        >>> N = 1  # num_classes\n",
        "        >>> kwargs = {\"alpha\": 0.25, \"gamma\": 2.0, \"reduction\": 'mean'}\n",
        "        >>> loss = BinaryFocalLossWithLogits(**kwargs)\n",
        "        >>> input = torch.randn(1, N, 3, 5, requires_grad=True)\n",
        "        >>> target = torch.empty(1, 3, 5, dtype=torch.long).random_(N)\n",
        "        >>> output = loss(input, target)\n",
        "        >>> output.backward()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha: float, gamma: float = 2.0,\n",
        "                 reduction: str = 'mean') -> None:\n",
        "        super(BinaryFocalLossWithLogits, self).__init__()\n",
        "        self.alpha: float = alpha\n",
        "        self.gamma: float = gamma\n",
        "        self.reduction: str = reduction\n",
        "        self.eps: float = 1e-8\n",
        "\n",
        "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        return binary_focal_loss_with_logits(\n",
        "            input, target, self.alpha, self.gamma, self.reduction, self.eps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXr7Djpv5pWU",
        "outputId": "455e0cb0-ea3c-4fa0-b3cc-211849f252c1"
      },
      "source": [
        "train_list = [1992, 2015, 2017, 1996, 2010, 2019, 1987, 1990, 1991, 2000, 2006, 1999, 2009, 2014, 2008, 1988, 1986, 1985]\n",
        "val_list = [1994, 2007, 2018, 2011, 2016, 1998, 1995, 2002]\n",
        "test_list =  [2001, 2003, 2005, 2012, 2013, 1989, 1993, 1997, 2004]\n",
        "len(train_list) + len(val_list) + len(test_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip5FEXDrUAp-"
      },
      "source": [
        "from transformers import AlbertConfig, AlbertModel\n",
        "\n",
        "class LenaTrans2(nn.Module):\n",
        "    def __init__(self, transactions_cat_features, \n",
        "                 embedding_projections, \n",
        "                 numerical_features,\n",
        "                 station_col_name='hydro_fixed_station_id_categorical', \n",
        "                 day_col_name='day_target_categorical', \n",
        "                 rnn_units=128, top_classifier_units=64, feat_trans_width = 64):\n",
        "        super(LenaTrans2, self).__init__()\n",
        "        self.numerical_features = list(numerical_features)\n",
        "        self.feat_trans_width = feat_trans_width\n",
        "        self._transaction_cat_embeddings = nn.ModuleList([self._create_embedding_projection(*embedding_projections[feature]) \n",
        "                                                          for feature in transactions_cat_features])\n",
        "        \n",
        "        self._product_embedding = self._create_embedding_projection(*embedding_projections[station_col_name], padding_idx=None)\n",
        "        self._day_embedding = self._create_embedding_projection(*embedding_projections[day_col_name], padding_idx=None)\n",
        "        \n",
        "        self._gru = nn.GRU(input_size=sum([embedding_projections[x][1] for x in transactions_cat_features]) + len(numerical_features),\n",
        "                             hidden_size=rnn_units, batch_first=True, bidirectional=False)\n",
        "        \n",
        "        self.feat_config = AlbertConfig( \n",
        "            3, # not used\n",
        "            embedding_size = 1,\n",
        "            hidden_size = feat_trans_width,\n",
        "            num_hidden_layers = 1,\n",
        "            num_attention_heads = 1,\n",
        "            intermediate_size = feat_trans_width,            \n",
        "            hidden_dropout_prob = 0.3,\n",
        "            attention_probs_dropout_prob = 0.3,\n",
        "            max_position_embeddings = sum([embedding_projections[x][1] for x in transactions_cat_features]) + len(numerical_features),\n",
        "            type_vocab_size = 1,\n",
        "            position_embedding_type = 'absolute'\n",
        "        )        \n",
        "        self.feat_encoder = AlbertModel(self.feat_config)\n",
        "\n",
        "        self.config = AlbertConfig( \n",
        "            3, # not used\n",
        "            embedding_size = feat_trans_width,\n",
        "            hidden_size = rnn_units,\n",
        "            num_hidden_layers = 1,\n",
        "            num_attention_heads = 2,\n",
        "            intermediate_size = rnn_units,            \n",
        "            hidden_dropout_prob = 0.3,\n",
        "            attention_probs_dropout_prob = 0.3,\n",
        "            max_position_embeddings = 139,\n",
        "            type_vocab_size = 1,\n",
        "            position_embedding_type = 'relative_key_query' \n",
        "        )        \n",
        "        self.encoder = AlbertModel(self.config)\n",
        "        \n",
        "        self._hidden_size = rnn_units\n",
        "                \n",
        "        self._head = nn.Sequential(\n",
        "            nn.Linear(rnn_units+embedding_projections[station_col_name][1]+embedding_projections[day_col_name][1], top_classifier_units),\n",
        "            nn.LayerNorm(top_classifier_units),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(top_classifier_units, top_classifier_units),\n",
        "            nn.LayerNorm(top_classifier_units),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(top_classifier_units, 1),            \n",
        "        )   \n",
        "    \n",
        "    def forward(self, transactions_cat_features, product_feature, day_feature):\n",
        "        batch_size = product_feature.shape[0]\n",
        "        \n",
        "        embeddings = [embedding(transactions_cat_features[:,:,i].long()) for i, embedding in enumerate(self._transaction_cat_embeddings)]\n",
        "        embeddings.append(transactions_cat_features[:,:,-len(self.numerical_features):].float())\n",
        "        concated_embeddings = torch.cat(embeddings, dim=-1)\n",
        "\n",
        "        seq_length = 139\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand((batch_size, seq_length))\n",
        "\n",
        "        mask = torch.ones((batch_size, seq_length))\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for j in range(seq_length):\n",
        "                if transactions_cat_features[i,j,:].sum() == 0:\n",
        "                    mask[i,j] = 0\n",
        "\n",
        "        encoded_feat_matrix = torch.zeros((batch_size, seq_length, self.feat_trans_width)).to(device)\n",
        "        feat_mask = torch.ones((batch_size, concated_embeddings.shape[2]))\n",
        "        feat_position_ids = torch.arange(concated_embeddings.shape[2], dtype=torch.long, device=device)\n",
        "        feat_position_ids = feat_position_ids.unsqueeze(0).expand((batch_size, concated_embeddings.shape[2]))\n",
        "\n",
        "        for i in range(seq_length):\n",
        "            out = self.feat_encoder(inputs_embeds=concated_embeddings[:,i,:].view((batch_size,concated_embeddings.shape[2],1)).to(device), \n",
        "                                    attention_mask=feat_mask.to(device), \n",
        "                                    position_ids=feat_position_ids.to(device))\n",
        "            feat_out = out[0]\n",
        "            feat_out = feat_out[:, -1]\n",
        "            encoded_feat_matrix[:,i,:] = feat_out\n",
        "        \n",
        "        encoded_layers = self.encoder(inputs_embeds=encoded_feat_matrix, \n",
        "                                      attention_mask=mask.to(device), \n",
        "                                      position_ids=position_ids.to(device))\n",
        "        sequence_output = encoded_layers[0]\n",
        "        sequence_output = sequence_output[:, -1]\n",
        "\n",
        "        product_embed = self._product_embedding(product_feature.long())\n",
        "        day_embed = self._day_embedding(day_feature.long())\n",
        "        \n",
        "        intermediate_concat = torch.cat([sequence_output, product_embed, day_embed], dim=-1)\n",
        "        \n",
        "        logit = self._head(intermediate_concat)\n",
        "        \n",
        "        return logit\n",
        "    \n",
        "    @classmethod\n",
        "    def _create_embedding_projection(cls, cardinality, embed_size, add_missing=False, padding_idx=0):\n",
        "        add_missing = 1 if add_missing else 0\n",
        "        return nn.Embedding(num_embeddings=cardinality+add_missing, embedding_dim=embed_size, padding_idx=padding_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "dcc2a5ac72c4410b9654fe4ec8441101",
            "73984031526841808741a95844896e90",
            "aa180367649546a7b61bf078e95aff40",
            "54a2318fd95e4631854f1ac258de4dad",
            "5c36b370159b4368a786308e089cdbc7",
            "940832be36b7494683bc5161fa1d558c",
            "0f3b28ba162b48f8b74346977b769297",
            "b480666723e14c7d8c3a18e438b0a12d"
          ]
        },
        "id": "H7Z21zH4kM4E",
        "outputId": "6592fea1-7c29-4cae-8916-b48b358dad7b"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "train_list = [1992, 2015, 2017, 1996, 2010, 2019, 1987, 1990, 1991, 2000, 2006, 1999, 2009, 2014, 2008, 1988, 1986, 1985]\n",
        "val_list = [1994, 2007, 2018, 2011, 2016, 1998, 1995, 2002]\n",
        "test_list =  [2001, 2003, 2005, 2012, 2013, 1989, 1993, 1997, 2004]\n",
        "\n",
        "train_ds = LenaDataset(train.loc[train.year.isin(train_list+val_list)], features_df, categorical_features, numerical_features)\n",
        "test_ds = LenaDataset(test, features_df, categorical_features, numerical_features)\n",
        "\n",
        "train_sampler = RandomSampler(train_ds)\n",
        "test_sampler = SequentialSampler(test_ds)\n",
        "batch_size = 32\n",
        "train_dl = DataLoader(train_ds, sampler=train_sampler, batch_size=batch_size, num_workers=2)\n",
        "test_dl = DataLoader(test_ds, sampler=test_sampler, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "lena_ai = LenaTrans2(categorical_features, transactions_cat_features, numerical_features).to(device)\n",
        "\n",
        "#criterion = torch.nn.BCEWithLogitsLoss(weight=torch.Tensor([80]))\n",
        "criterion = BinaryFocalLossWithLogits(alpha=0.25, gamma=2.5)\n",
        "criterion.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(lena_ai.parameters(),\n",
        "                       lr=1e-3,\n",
        "                       weight_decay=0.001,                           \n",
        "                       )\n",
        "\n",
        "'''\n",
        "nepochs = 5\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "    lena_ai.train();\n",
        "    optimizer.zero_grad()\n",
        "    i = 0\n",
        "    for x in tqdm.tqdm_notebook(train_dl):\n",
        "        out = lena_ai(x['x'].float().to(device), x['station'].long().to(device), x['day'].long().to(device))\n",
        "        loss = criterion(out, x['y'].float().to(device)) #.mean()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(lena_ai.parameters(), 100.0)\n",
        "        optimizer.step() \n",
        "        optimizer.zero_grad()\n",
        "        i += 1\n",
        "        #if i % 10 == 0:\n",
        "        #    print(loss.item())\n",
        "\n",
        "torch.save(lena_ai.state_dict(), 'lena_ai_trans.pth')\n",
        "'''\n",
        "\n",
        "lena_ai.load_state_dict(torch.load('lena_ai_trans.pth'))\n",
        "\n",
        "lena_ai.eval();\n",
        "test_preds = []\n",
        "m = torch.nn.Sigmoid()\n",
        "with torch.no_grad():\n",
        "    for x in tqdm.tqdm_notebook(test_dl): #tqdm.notebook.tqdm(valid_dl):\n",
        "        out = lena_ai(x['x'].float().to(device), x['station'].long().to(device), x['day'].long().to(device))\n",
        "        out = m(out).detach().cpu().numpy()\n",
        "        test_preds.append(out)\n",
        "full_preds = np.vstack(test_preds).ravel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcc2a5ac72c4410b9654fe4ec8441101",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=123.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOoi-d00D126",
        "outputId": "17d748d1-f6da-46fa-e288-a6d837bcbd19"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3906, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "vEz0W9cFl__l",
        "outputId": "bd9d3435-607c-402d-ef0e-4660603a65a6"
      },
      "source": [
        "test.ice_jam = (full_preds > 0.231).astype(int)\n",
        "print(test.ice_jam.mean(), train.ice_jam.mean())\n",
        "test.loc[test.ice_jam == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.029953917050691243 0.01223729715349827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>station_id</th>\n",
              "      <th>day</th>\n",
              "      <th>ice_jam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>772</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476</th>\n",
              "      <td>1993</td>\n",
              "      <td>3230</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>1993</td>\n",
              "      <td>3230</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>1997</td>\n",
              "      <td>3230</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>1997</td>\n",
              "      <td>3230</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521</th>\n",
              "      <td>1997</td>\n",
              "      <td>3230</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      year  station_id  day  ice_jam\n",
              "758   2001        3030   10        1\n",
              "764   2001        3030   16        1\n",
              "769   2001        3030   21        1\n",
              "771   2001        3030   23        1\n",
              "772   2001        3030   24        1\n",
              "...    ...         ...  ...      ...\n",
              "1476  1993        3230   24        1\n",
              "1477  1993        3230   25        1\n",
              "1519  1997        3230   23        1\n",
              "1520  1997        3230   24        1\n",
              "1521  1997        3230   25        1\n",
              "\n",
              "[117 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "p4sewzbklc50",
        "outputId": "082417f4-5b60-4e2d-f80f-3ad19356a563"
      },
      "source": [
        "test.ice_jam = (full_preds > 0.23).astype(int)\n",
        "print(test.ice_jam.mean(), train.ice_jam.mean())\n",
        "test.loc[test.ice_jam == 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.03456221198156682 0.01223729715349827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>station_id</th>\n",
              "      <th>day</th>\n",
              "      <th>ice_jam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>772</th>\n",
              "      <td>2001</td>\n",
              "      <td>3030</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476</th>\n",
              "      <td>1993</td>\n",
              "      <td>3230</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>1993</td>\n",
              "      <td>3230</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>1997</td>\n",
              "      <td>3230</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>1997</td>\n",
              "      <td>3230</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521</th>\n",
              "      <td>1997</td>\n",
              "      <td>3230</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>135 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      year  station_id  day  ice_jam\n",
              "758   2001        3030   10        1\n",
              "764   2001        3030   16        1\n",
              "769   2001        3030   21        1\n",
              "771   2001        3030   23        1\n",
              "772   2001        3030   24        1\n",
              "...    ...         ...  ...      ...\n",
              "1476  1993        3230   24        1\n",
              "1477  1993        3230   25        1\n",
              "1519  1997        3230   23        1\n",
              "1520  1997        3230   24        1\n",
              "1521  1997        3230   25        1\n",
              "\n",
              "[135 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMW49h-9a-Cd",
        "outputId": "4062c93b-f69e-45b5-e398-e462888fdc0c"
      },
      "source": [
        "test.loc[test.ice_jam == 1,'station_id'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3030, 3230])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIc7Z9T7bCV8",
        "outputId": "b8a5ac81-4f7d-4d4c-fda0-e4afbba72094"
      },
      "source": [
        "test.loc[test.ice_jam == 1,'year'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2001, 2003, 2004, 2005, 2012, 2013, 1989, 1993, 1997])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9jDxOO_TlGXz",
        "outputId": "364c7fda-65aa-49b4-fd78-232eaa1e659c"
      },
      "source": [
        "test.to_csv('lena_ai_trans_on_trans2.csv', index=False)\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>station_id</th>\n",
              "      <th>day</th>\n",
              "      <th>ice_jam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>3019</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>3019</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>3019</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>3019</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>3019</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  station_id  day  ice_jam\n",
              "0  2001        3019    0        0\n",
              "1  2001        3019    1        0\n",
              "2  2001        3019    2        0\n",
              "3  2001        3019    3        0\n",
              "4  2001        3019    4        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfxOX6PrYeMb",
        "outputId": "875021e9-dab5-4742-e591-2036cf79cd41"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 29 05:47:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    33W / 250W |   1099MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
